Classic **Kubernetes / EKS interview scenario** ğŸ‘Œ
Letâ€™s answer it the way an interviewer expects: **clear reasons + how to verify**.

---

## Scenario

ğŸ‘‰ Deployment replicas = **5**
ğŸ‘‰ Only **3 pods are running**

This means **2 pods failed to schedule or failed to start**.

---

## Most common reasons (in order of probability)

### âœ… **1. Insufficient cluster resources (MOST COMMON)**

Nodes donâ€™t have enough:

* CPU
* Memory

Check:

```bash
kubectl describe deployment <deploy-name>
kubectl describe pod <pending-pod>
```

Youâ€™ll see:

```
0/3 nodes are available: Insufficient cpu
```

âœ” Fix:

* Add nodes (Cluster Autoscaler)
* Reduce resource requests

---

### âœ… **2. Pod stuck in Pending state**

Pods are created but **scheduler canâ€™t place them**.

Check:

```bash
kubectl get pods
```

If status = `Pending` â†’ scheduling issue.

---

### âœ… **3. NodeSelector / Affinity / Taints**

Pods restricted to certain nodes.

Examples:

* `nodeSelector`
* `nodeAffinity`
* Node taints without tolerations

Result:

* Only some nodes eligible

Check:

```bash
kubectl describe pod <pod-name>
```

---

### âœ… **4. Pod IP exhaustion (EKS VERY COMMON ğŸ”¥)**

Subnet doesnâ€™t have enough free IPs.

Symptoms:

* Pod stuck in `ContainerCreating`
* Event:

```
failed to assign an IP address to container
```

Check:

```bash
kubectl logs -n kube-system aws-node
```

âœ” Fix:

* Larger subnet
* Prefix delegation
* Add secondary CIDR

---

### âœ… **5. Image pull issues**

If pods crash during startup.

Status:

* `ImagePullBackOff`
* `ErrImagePull`

Check:

```bash
kubectl describe pod
```

---

### âœ… **6. CrashLoopBackOff**

Pods start then crash.

Only running pods are counted as **Running**.

Check logs:

```bash
kubectl logs <pod>
```

---

### âœ… **7. PodDisruptionBudget (PDB)**

PDB restricts number of pods running.

Example:

```yaml
minAvailable: 3
```

Kubernetes wonâ€™t bring all replicas up.

---

### âœ… **8. Quota limits**

Namespace-level quotas limit:

* Pods
* CPU
* Memory

Check:

```bash
kubectl get resourcequota
```

---

## Quick debugging flow (interview gold â­)

```bash
kubectl get pods
kubectl describe pod <non-running-pod>
kubectl get nodes
kubectl describe deployment <deploy>
kubectl get events --sort-by=.metadata.creationTimestamp
```

---

## Interview-ready answer ğŸ¯

> If a Deployment requests 5 replicas but only 3 are running, it usually means the remaining pods could not be scheduled or started. Common causes include insufficient node resources, node affinity or taints, pod IP exhaustion in EKS, image pull errors, CrashLoopBackOff, PodDisruptionBudgets, or namespace resource quotas.

---

## One-liner (senior-level ğŸ”¥)

> If replicas are not matching in a Deployment, always check pod events firstâ€”Kubernetes tells you exactly why.

If you want:

* ğŸ§  **EKS-specific follow-up questions**
* ğŸ”¥ **Real prod outage explanation**
* ğŸ§ª **Mock interview drill**

Just say ğŸ‘
